CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz
    Hardware threads: 40
    Total Memory: 264046996 kB
-------------------------------------------------------------------
=== Preparing training and test data
=== Running training
=== Running /mnt/Data/nikmil/cntk/gpu/release/bin/cntk configFile=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/fcn.cntk currentDirectory=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data RunDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu DataDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data ConfigDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN OutputDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu DeviceId=0 timestamping=true
CNTK 2.0rc1+ (fcn_test 3ff926, Apr 12 2017 08:11:43) on ASAUDGPU1 at 2017/04/13 05:53:09

/mnt/Data/nikmil/cntk/gpu/release/bin/cntk  configFile=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/fcn.cntk  currentDirectory=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data  RunDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu  DataDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data  ConfigDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN  OutputDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data
ping [requestnodes (before change)]: 1 nodes pinging each other
ping [requestnodes (after change)]: 1 nodes pinging each other
requestnodes [MPIWrapperMpi]: using 1 out of 1 MPI nodes on a single host (1 requested); we (0) are in (participating)
ping [mpihelper]: 1 nodes pinging each other
04/13/2017 05:53:27: -------------------------------------------------------------------
04/13/2017 05:53:27: Build info: 

04/13/2017 05:53:27: 		Built time: Apr 12 2017 08:10:36
04/13/2017 05:53:27: 		Last modified date: Tue Apr 11 07:31:08 2017
04/13/2017 05:53:27: 		Build type: release
04/13/2017 05:53:27: 		Build target: GPU
04/13/2017 05:53:27: 		With 1bit-SGD: no
04/13/2017 05:53:27: 		With ASGD: yes
04/13/2017 05:53:27: 		Math lib: mkl
04/13/2017 05:53:27: 		CUDA_PATH: /usr/local/cuda-7.5
04/13/2017 05:53:27: 		CUB_PATH: /usr/local/cub-1.4.1
04/13/2017 05:53:27: 		CUDNN_PATH: /usr/local/cudnn-5.1
04/13/2017 05:53:27: 		Build Branch: fcn_test
04/13/2017 05:53:27: 		Build SHA1: 3ff92650936c972c8025eaf37d40ec64ca16ae16 (modified)
04/13/2017 05:53:27: 		Built by Source/CNTK/buildinfo.h$$0 on ASAUDGPU1
04/13/2017 05:53:27: 		Build Path: /mnt/Data/nikmil/cntk/
04/13/2017 05:53:27: 		MPI distribution: Open MPI
04/13/2017 05:53:27: 		MPI version: 1.10.2
04/13/2017 05:53:27: -------------------------------------------------------------------
04/13/2017 05:53:27: -------------------------------------------------------------------
04/13/2017 05:53:27: GPU info:

04/13/2017 05:53:27: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: 		Device[4]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: 		Device[5]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: 		Device[6]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: 		Device[7]: cores = 2880; computeCapability = 3.5; type = "Tesla K40m"; total memory = 11519 MB; free memory = 11463 MB
04/13/2017 05:53:27: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: fcn.cntk:ClassCount=2
configparameters: fcn.cntk:command=TrainFCN8:ConvertFCN8ToFCN4:TrainFCN4:PrepareFCN4ForTest:TestFCN4
configparameters: fcn.cntk:ConfigDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN
configparameters: fcn.cntk:ConvertFCN8ToFCN4=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train_miouError"
    NewModel = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_initial"
    editPath = "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/fcn8_to_fcn4.mel"
]

configparameters: fcn.cntk:currentDirectory=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:DataDir=/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/Data
configparameters: fcn.cntk:deviceId=0
configparameters: fcn.cntk:Epochs=2
configparameters: fcn.cntk:FcnDataDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Data
configparameters: fcn.cntk:FeatureChannels=16
configparameters: fcn.cntk:ImageChannels=1
configparameters: fcn.cntk:LrPerSample=0.01
configparameters: fcn.cntk:MbSize=16
configparameters: fcn.cntk:ModelDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models
configparameters: fcn.cntk:MomentumTimeConstant=1215
configparameters: fcn.cntk:numMBsToShowResult=1
configparameters: fcn.cntk:OutputDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu
configparameters: fcn.cntk:parallelTrain=true
configparameters: fcn.cntk:precision=float
configparameters: fcn.cntk:PrepareFCN4ForTest=[
    action = "edit"
    CurModel = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train_miouError"
    NewModel = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_test"
    editPath = "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/prepare_for_test.mel"
    TestImageHeight = 28
    TestImageWidth = 28
    ImageChannels = 1
    ClassCount = 2
]

configparameters: fcn.cntk:RunDir=/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu
configparameters: fcn.cntk:TestDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:TestFCN4=[
    action = test
    numMBsToShowResult = 20
    modelPath = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_test"
    minibatchSize = 16
distributedMBReading = "true" 
    BrainScriptNetworkBuilder = [
        m = BS.Network.Load("/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_test")
        evaluationNodes = (m.pixelwiseError:m.miouError)
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TestFeaturesDim=784
configparameters: fcn.cntk:TestIgnoreDim=784
configparameters: fcn.cntk:TestImageHeight=28
configparameters: fcn.cntk:TestImageWidth=28
configparameters: fcn.cntk:TestLabelsDim=1568
configparameters: fcn.cntk:timestamping=true
configparameters: fcn.cntk:traceLevel=1
configparameters: fcn.cntk:TrainDataFile=Train_cntk_fcn_text.txt
configparameters: fcn.cntk:TrainFCN4=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        featureChannels = 16
        inModel = BS.Network.Load("/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_initial")
        predictionFCN4 = ConvLayer1x1MSRAInit(inModel.featuresFCN4, featureChannels, classCount, 1, 1)
        upsampledFCN8 = LearnableUpsamplingLayer{classCount, classCount, 4, 2}(inModel.predictionFCN8)
        cropFCN8 = CropAutomatic(upsampledFCN8, predictionFCN4)
        fusionFCN4 = Plus(cropFCN8, predictionFCN4)
        upsampledFCN4 = BilinearUpsamplingLayer{classCount, classCount, 8, 4}(fusionFCN4)
        out = CropAutomaticGivenAncestors(upsampledFCN4, inModel.labels, inModel.features, inModel.labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(inModel.labels, out, inModel.ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(inModel.labels, out, inModel.ignoreMask)
        miouError = MeanIOUError(inModel.labels, out, inModel.ignoreMask, classCount = classCount)
        featureNodes    = (inModel.features)
        labelNodes      = (inModel.labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant= 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFCN8=[
    action = "train"
    modelPath = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train"
    saveBestModelPerCriterion = "true"
    BrainScriptNetworkBuilder = [
        include "/mnt/Data/nikmil/cntk/Tests/EndToEndTests/Image/FCN/shared.bs"
        classCount = 2
        imageWidth = 28
        imageHeight = 28
        imageChannels = 1
        featureChannels = 16
        bnTimeConst = 15992
        features = ImageInput(imageWidth, imageHeight, imageChannels, imageLayout = "cudnn", tag = 'feature')
        labels = ImageInput(imageWidth, imageHeight, classCount, imageLayout = "cudnn", tag = 'label')
        ignoreMask = ImageInput(imageWidth, imageHeight, 1, imageLayout = "cudnn", tag = 'feature')
        featuresFCN4 = Sequential(
            ConvBNReLULayer{featureChannels, /*kernel*/ (7:7), /*stride*/ (2:2), bnTimeConst} :
            MaxPoolingLayer{(3:3), stride = 2, pad = true})(features)
        featuresFCN8 = Sequential(
            ResNetBasicInc{featureChannels, /*stride*/ (2:2), bnTimeConst} :
            ResNetBasic{featureChannels, bnTimeConst})(featuresFCN4)
        predictionFCN8 = ConvLayer1x1MSRAInit(featuresFCN8, featureChannels, classCount, 1, 1)
        upsampledFCN8 = BilinearUpsamplingLayer{classCount, classCount, 16, 8}(predictionFCN8)
        out = CropAutomaticGivenAncestors(upsampledFCN8, labels, features, labels)
        CE = CrossEntropyWithSoftmaxNDNormalized(labels, out, ignoreMask, axis = 3, tag = 'criterion')
        pixelwiseError = PixelError(labels, out, ignoreMask)
        miouError = MeanIOUError(labels, out, ignoreMask, classCount = classCount)
        featureNodes    = (features)
        labelNodes      = (labels)
        criterionNodes  = (CE)
        evaluationNodes = (pixelwiseError:miouError)
        outputNodes     = (out)
    ]
    SGD = [
        minibatchSize = 16
        learningRatesPerSample = 0.01
        momentumAsTimeConstant = 1215
        maxEpochs = 2
        gradUpdateType = "None"
        L2RegWeight = 0.00000390625
        dropoutRate = 0
        minLearningRatePerSample = 1e-15
disableWkInBatchNormal = "true" 
        ParallelTrain = [
            parallelizationMethod = "DataParallelSGD"
            distributedMBReading = "true"
            parallelizationStartEpoch = 1
            DataParallelSGD = [
                gradientBits = 32
            ]
        ]
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Data/Train_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
    cvReader = [
        readerType = "CNTKTextFormatReader"
        file = "/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Data/Test_cntk_fcn_text.txt"
        input = [
            features = [
                dim = 784
                format = "dense"
            ]
            labels = [
                dim = 1568
                format = "dense"
            ]
            ignoreMask = [
                dim = 784
                format = "dense"
            ]
        ]
    ]
]

configparameters: fcn.cntk:TrainFeaturesDim=784
configparameters: fcn.cntk:TrainIgnoreDim=784
configparameters: fcn.cntk:TrainImageHeight=28
configparameters: fcn.cntk:TrainImageWidth=28
configparameters: fcn.cntk:TrainLabelsDim=1568
configparameters: fcn.cntk:ValDataFile=Test_cntk_fcn_text.txt
configparameters: fcn.cntk:WeightDecay=0.00000390625
04/13/2017 05:53:27: Commands: TrainFCN8 ConvertFCN8ToFCN4 TrainFCN4 PrepareFCN4ForTest TestFCN4
04/13/2017 05:53:27: precision = "float"

04/13/2017 05:53:27: ##############################################################################
04/13/2017 05:53:27: #                                                                            #
04/13/2017 05:53:27: # TrainFCN8 command (train action)                                           #
04/13/2017 05:53:27: #                                                                            #
04/13/2017 05:53:27: ##############################################################################

04/13/2017 05:53:27: 
Creating virgin network.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[3 x 3 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[7 x 7 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[1 x 1 x 0 x 16] as heNormal later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.
Node '<placeholder>' (LearnableParameter operation): Initializating Parameter[0 x 1] as fromValue later when dimensions are fully known.

Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 108 nodes to process in pass 1.

Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 0 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 0 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [7 x 7 x 1 x 16].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[7 x 7 x 1 x 16] <- heNormal(seed=6, init dims=[784 x 49], range=0.202031(0.202031*1.000000), onCPU=true.
)Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *] -> [14 x 14 x 16 x *]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *] -> [7 x 7 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=5, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=4, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 0 x 16]
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [1 x 1 x 16 x 16].
Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[1 x 1 x 16 x 16] <- heNormal(seed=7, init dims=[16 x 16], range=0.353553(0.353553*1.000000), onCPU=true.
)Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.x.s.arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=3, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) operation: Tensor shape was inferred as [3 x 3 x 16 x 16].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation): Initializing Parameter[3 x 3 x 16 x 16] <- heNormal(seed=2, init dims=[144 x 144], range=0.117851(0.117851*1.000000), onCPU=true.
)Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [0 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 1.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation) operation: Tensor shape was inferred as [16 x 1].
Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance' (LearnableParameter operation): Initializing Parameter[16 x 1] <- 0.000000.
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *], [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *] -> [4 x 4 x 16 x *]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *] -> [4 x 4 x 2 x *]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [16 x 16 x 2 x 2], [4 x 4 x 2 x *] -> [40 x 40 x 2 x *]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *]
Validating --> out = Crop (upsampledFCN8, labels, features, labels) : [40 x 40 x 2 x *], [28 x 28 x 2 x *], [28 x 28 x 1 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *] -> [784 x 2 x *]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *] -> [1 x 2 x *]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *], [28 x 28 x 1 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *], [28 x 28 x 2 x *] -> [28 x 28 x 2 x *]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *], [28 x 28 x 1 x *] -> [28 x 28 x 1 x *]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *] -> [1 x *]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *] -> [1 x *]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *], [1 x *] -> [1 x *]

Validating network. 64 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using cuDNN convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

04/13/2017 05:53:28: 
Model has 108 nodes. Using GPU 0.

04/13/2017 05:53:28: Training criterion:   CE = ElementTimes

04/13/2017 05:53:28: Evaluation criteria:
04/13/2017 05:53:28: 	pixelwiseError = ElementTimes
04/13/2017 05:53:28: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 159 matrices, 96 are shared as 26, and 63 are not shared.

Here are the ones that share memory:
	{ featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *] (gradient)
	  upsampledFCN8 : [40 x 40 x 2 x *] }
	{ CE.out_shift : [28 x 28 x 2 x *]
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ featuresFCN8.x.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *] }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.p : [4 x 4 x 16 x *]
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient) }
	{ CE.diff_valid : [28 x 28 x 1 x *] (gradient)
	  CE.logits.r : [28 x 28 x 1 x *] (gradient)
	  CE.out_shift : [28 x 28 x 2 x *] (gradient)
	  featuresFCN4 : [7 x 7 x 16 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.intersection : [28 x 28 x 2 x *]
	  miouError.unionFlat : [784 x 2 x *]
	  pixelwiseError.acc._ : [28 x 28 x 2 x *]
	  pixelwiseError.diffs : [28 x 28 x 1 x *] }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] }
	{ CE.out_max.r : [28 x 28 x 1 x *]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *]
	  featuresFCN8.x.s : [4 x 4 x 16 x *] }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *] }
	{ CE.log_sum.r : [28 x 28 x 1 x *]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }
	{ featuresFCN4.x : [14 x 14 x 16 x *]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *] (gradient) }
	{ CE.log_sum.r : [28 x 28 x 1 x *] (gradient)
	  CE.out_max.r : [28 x 28 x 1 x *] (gradient)
	  featuresFCN8 : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  pixelwiseError.acc.r : [28 x 28 x 1 x *]
	  pixelwiseError.pixelNorm.z.r : [1 x *] }
	{ CE : [1] (gradient)
	  CE.norm_factor.z : [1]
	  miouError.miou : [1] }
	{ featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *] }
	{ featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *] }
	{ featuresFCN8 : [4 x 4 x 16 x *]
	  featuresFCN8.b : [4 x 4 x 16 x *]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *] (gradient) }
	{ featuresFCN8.x.b.x._ : [4 x 4 x 16 x *]
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *] }
	{ CE.diff : [28 x 28 x 1 x *] (gradient)
	  CE.logits_per_class : [28 x 28 x 2 x *]
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *]
	  out : [28 x 28 x 2 x *] (gradient) }
	{ CE.ce_unnorm : [1]
	  featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  out : [28 x 28 x 2 x *] }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.u : [1 x 2] }
	{ featuresFCN8.p : [4 x 4 x 16 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *]
	  miouError.intersectionByClass.r : [1 x 2 x *]
	  miouError.unionByClass.r : [1 x 2 x *]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *] }
	{ CE.diff : [28 x 28 x 1 x *]
	  featuresFCN8.x.b : [4 x 4 x 16 x *] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *] (gradient) }
	{ CE.logits_per_class : [28 x 28 x 2 x *] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *]
	  miouError.intersectionFlat : [784 x 2 x *]
	  miouError.union : [28 x 28 x 2 x *]
	  upsampledFCN8 : [40 x 40 x 2 x *] (gradient) }
	{ CE.diff_valid : [28 x 28 x 1 x *]
	  CE.logits.r : [28 x 28 x 1 x *]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *] }

Here are the ones that don't share memory:
	{miouError.norm.z : [1]}
	{upsampledFCN8.W : [16 x 16 x 2 x 2]}
	{predictionFCN8.W : [2 x 16]}
	{ignoreMask : [28 x 28 x 1 x *]}
	{labels : [28 x 28 x 2 x *]}
	{BS.Constants.One : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{features : [28 x 28 x 1 x *]}
	{pixelwiseError : [1 x *]}
	{miouError : [1]}
	{CE : [1]}
	{miouError.norm : [1]}
	{pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *]}
	{miouError.labelMasked : [28 x 28 x 2 x *]}
	{miouError.reciprocalUnion : [1 x 2]}
	{CE.norm_factor : [1]}
	{predictionFCN8.W : [2 x 16] (gradient)}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *]}
	{pixelwiseError.pixelNorm : [1 x *]}
	{miouError.i : [1 x 2]}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *]}
	{miouError.iouSum.r : [1]}
	{miouError.outHardmax.isMax : [28 x 28 x 2 x *]}
	{pixelwiseError.errSum.r : [1 x *]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *]}
	{miouError.outMasked : [28 x 28 x 2 x *]}
	{featuresFCN4 : [7 x 7 x 16 x *]}


04/13/2017 05:53:28: Training 10480 parameters in 19 out of 19 parameter tensors and 51 nodes with gradient:

04/13/2017 05:53:28: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
04/13/2017 05:53:28: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:28: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:28: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:28: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]

Initializing dataParallelSGD with FP32 aggregation.
04/13/2017 05:53:28: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

04/13/2017 05:53:28: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/13/2017 05:53:28: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05358126 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67398942 * 1; time = 0.2174s; samplesPerSecond = 73.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05348113 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67441511 * 1; time = 0.0380s; samplesPerSecond = 421.1
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05336733 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67430866 * 1; time = 0.0034s; samplesPerSecond = 4743.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368700 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67455792 * 1; time = 0.0032s; samplesPerSecond = 5046.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05335811 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67504084 * 1; time = 0.0030s; samplesPerSecond = 5305.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05369276 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67514026 * 1; time = 0.0032s; samplesPerSecond = 5035.1
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05265899 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67507046 * 1; time = 0.0032s; samplesPerSecond = 4950.1
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05230937 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67532289 * 1; time = 0.0037s; samplesPerSecond = 4304.1
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05198928 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67511535 * 1; time = 0.0031s; samplesPerSecond = 5125.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05222526 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67508686 * 1; time = 0.0031s; samplesPerSecond = 5111.4
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05389462 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67506295 * 1; time = 0.0032s; samplesPerSecond = 5042.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05333263 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67526424 * 1; time = 0.0032s; samplesPerSecond = 4992.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05272814 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67540675 * 1; time = 0.0037s; samplesPerSecond = 4325.3
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05209519 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67514789 * 1; time = 0.0037s; samplesPerSecond = 4320.7
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05225396 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67502189 * 1; time = 0.0036s; samplesPerSecond = 4467.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05167080 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67490757 * 1; time = 0.0031s; samplesPerSecond = 5135.2
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05176315 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.67495859 * 1; time = 0.0032s; samplesPerSecond = 4988.3
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05266294 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67491794 * 1; time = 0.0030s; samplesPerSecond = 5390.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05159564 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67501092 * 1; time = 0.0033s; samplesPerSecond = 4855.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05183941 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67500407 * 1; time = 0.0036s; samplesPerSecond = 4418.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05289968 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67495596 * 1; time = 0.0036s; samplesPerSecond = 4490.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05099520 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.67506927 * 1; time = 0.0031s; samplesPerSecond = 5122.4
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05251543 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67518246 * 1; time = 0.0030s; samplesPerSecond = 5396.1
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05193302 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67510211 * 1; time = 0.0031s; samplesPerSecond = 5096.4
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05142954 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67501867 * 1; time = 0.0031s; samplesPerSecond = 5098.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05142086 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67494607 * 1; time = 0.0032s; samplesPerSecond = 5065.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05044030 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67490304 * 1; time = 0.0032s; samplesPerSecond = 5001.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05047078 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67470390 * 1; time = 0.0029s; samplesPerSecond = 5433.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05127440 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67464459 * 1; time = 0.0032s; samplesPerSecond = 5076.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05085520 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67467296 * 1; time = 0.0031s; samplesPerSecond = 5129.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05155106 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67465842 * 1; time = 0.0031s; samplesPerSecond = 5125.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.05023826 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67464674 * 1; time = 0.0029s; samplesPerSecond = 5466.8
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.05065093 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67471075 * 1; time = 0.0030s; samplesPerSecond = 5333.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.05021257 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67462003 * 1; time = 0.0031s; samplesPerSecond = 5091.3
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.05021331 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67457265 * 1; time = 0.0032s; samplesPerSecond = 5072.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04962941 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67442656 * 1; time = 0.0032s; samplesPerSecond = 5027.8
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04995881 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67431742 * 1; time = 0.0029s; samplesPerSecond = 5494.2
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04905782 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67424840 * 1; time = 0.0031s; samplesPerSecond = 5223.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04903949 * 16; pixelwiseError = 0.49872449 * 16; miouError = 0.67405808 * 1; time = 0.0032s; samplesPerSecond = 4987.2
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04942059 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67393017 * 1; time = 0.0032s; samplesPerSecond = 5020.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04903770 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.67384559 * 1; time = 0.0032s; samplesPerSecond = 5031.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04925745 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67371130 * 1; time = 0.0030s; samplesPerSecond = 5354.2
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04858891 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.67352635 * 1; time = 0.0032s; samplesPerSecond = 5032.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04879065 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67342913 * 1; time = 0.0032s; samplesPerSecond = 4989.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04846421 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67336792 * 1; time = 0.0032s; samplesPerSecond = 4957.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04976217 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67332244 * 1; time = 0.0031s; samplesPerSecond = 5169.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04835905 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67324567 * 1; time = 0.0030s; samplesPerSecond = 5348.3
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04839681 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.67312360 * 1; time = 0.0032s; samplesPerSecond = 4962.8
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04807591 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67301494 * 1; time = 0.0032s; samplesPerSecond = 4957.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04864993 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.67287564 * 1; time = 0.0032s; samplesPerSecond = 4987.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04807357 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67276645 * 1; time = 0.0030s; samplesPerSecond = 5357.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04832945 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67266506 * 1; time = 0.0038s; samplesPerSecond = 4164.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04854266 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.67255116 * 1; time = 0.0037s; samplesPerSecond = 4370.9
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04867917 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67244184 * 1; time = 0.0033s; samplesPerSecond = 4895.7
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04762788 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67233729 * 1; time = 0.0032s; samplesPerSecond = 4952.4
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04807315 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67224872 * 1; time = 0.0030s; samplesPerSecond = 5401.0
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04766794 * 16; pixelwiseError = 0.50071752 * 16; miouError = 0.67212498 * 1; time = 0.0032s; samplesPerSecond = 4993.1
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04836555 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67193913 * 1; time = 0.0032s; samplesPerSecond = 4965.1
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04791102 * 16; pixelwiseError = 0.49904338 * 16; miouError = 0.67184687 * 1; time = 0.0032s; samplesPerSecond = 4978.2
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04734936 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67173946 * 1; time = 0.0030s; samplesPerSecond = 5292.5
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04762774 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67164212 * 1; time = 0.0030s; samplesPerSecond = 5278.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04713606 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.67150939 * 1; time = 0.0033s; samplesPerSecond = 4916.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09483323 * 8; pixelwiseError = 0.50000000 * 8; miouError = 0.67144459 * 1; time = 0.0057s; samplesPerSecond = 1410.6
04/13/2017 05:53:28:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67144459 * 1; time = 0.0007s; samplesPerSecond = 0.0
04/13/2017 05:53:28: Finished Epoch[ 1 of 2]: [Training] CE = 0.05085723 * 1000; pixelwiseError = 0.49977423 * 1000; miouError = 0.67144459 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=0.502218s
04/13/2017 05:53:28: Final Results: Minibatch[1-8]: CE = 0.05367580 * 100; pixelwiseError = 0.50012756 * 100; miouError = 0.66783661 * 1
04/13/2017 05:53:28: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05367580 * 100; pixelwiseError = 0.50012756 * 100; miouError = 0.66783661 * 1
04/13/2017 05:53:28: Best epoch per criterion so far: [Validate] CE = 0.053676 (Epoch 1); pixelwiseError = 0.500128 (Epoch 1); miouError = 0.667837 (Epoch 1)
04/13/2017 05:53:28: SGD: Saving checkpoint model '/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train.1'

04/13/2017 05:53:28: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/13/2017 05:53:28: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04700519 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66612023 * 1; time = 0.0034s; samplesPerSecond = 4657.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04714876 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66607058 * 1; time = 0.0030s; samplesPerSecond = 5264.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04765578 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66636401 * 1; time = 0.0030s; samplesPerSecond = 5319.4
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04804923 * 16; pixelwiseError = 0.50079721 * 16; miouError = 0.66675544 * 1; time = 0.0038s; samplesPerSecond = 4167.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04675569 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66669500 * 1; time = 0.0036s; samplesPerSecond = 4445.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04724479 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66669518 * 1; time = 0.0036s; samplesPerSecond = 4463.1
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04702438 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66650820 * 1; time = 0.0036s; samplesPerSecond = 4437.5
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04676031 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66648334 * 1; time = 0.0036s; samplesPerSecond = 4492.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04685747 * 16; pixelwiseError = 0.49944198 * 16; miouError = 0.66642678 * 1; time = 0.0036s; samplesPerSecond = 4496.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04695185 * 16; pixelwiseError = 0.50103641 * 16; miouError = 0.66651678 * 1; time = 0.0039s; samplesPerSecond = 4102.7
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04675236 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.66656190 * 1; time = 0.0048s; samplesPerSecond = 3358.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04688483 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66650724 * 1; time = 0.0036s; samplesPerSecond = 4461.7
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04710712 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.66653931 * 1; time = 0.0039s; samplesPerSecond = 4153.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04658839 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.66656166 * 1; time = 0.0044s; samplesPerSecond = 3613.5
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04683050 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66656494 * 1; time = 0.0042s; samplesPerSecond = 3816.2
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04657680 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652799 * 1; time = 0.0042s; samplesPerSecond = 3847.4
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04679916 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66655302 * 1; time = 0.0037s; samplesPerSecond = 4304.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04660954 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652727 * 1; time = 0.0031s; samplesPerSecond = 5217.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04645366 * 16; pixelwiseError = 0.49840561 * 16; miouError = 0.66646540 * 1; time = 0.0036s; samplesPerSecond = 4415.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04691650 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.66647780 * 1; time = 0.0036s; samplesPerSecond = 4404.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04672623 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66648328 * 1; time = 0.0039s; samplesPerSecond = 4128.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04685799 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66649449 * 1; time = 0.0034s; samplesPerSecond = 4668.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04632717 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.66652131 * 1; time = 0.0035s; samplesPerSecond = 4584.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04620084 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66652411 * 1; time = 0.0036s; samplesPerSecond = 4434.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04644240 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66655266 * 1; time = 0.0035s; samplesPerSecond = 4524.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04647168 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.66662550 * 1; time = 0.0034s; samplesPerSecond = 4640.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04656660 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.66658986 * 1; time = 0.0036s; samplesPerSecond = 4501.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04652067 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66661513 * 1; time = 0.0035s; samplesPerSecond = 4513.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04621993 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66658849 * 1; time = 0.0034s; samplesPerSecond = 4713.4
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04661596 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66662574 * 1; time = 0.0035s; samplesPerSecond = 4594.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04641042 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66667020 * 1; time = 0.0035s; samplesPerSecond = 4535.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04644848 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66669607 * 1; time = 0.0035s; samplesPerSecond = 4552.9
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04617932 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66668630 * 1; time = 0.0035s; samplesPerSecond = 4623.7
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04607057 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66672164 * 1; time = 0.0034s; samplesPerSecond = 4650.9
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04620295 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.66673583 * 1; time = 0.0031s; samplesPerSecond = 5088.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04600681 * 16; pixelwiseError = 0.49864474 * 16; miouError = 0.66672814 * 1; time = 0.0031s; samplesPerSecond = 5123.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04620455 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66676486 * 1; time = 0.0033s; samplesPerSecond = 4831.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04619166 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.66678202 * 1; time = 0.0029s; samplesPerSecond = 5518.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04603130 * 16; pixelwiseError = 0.49776784 * 16; miouError = 0.66675997 * 1; time = 0.0030s; samplesPerSecond = 5300.4
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04587509 * 16; pixelwiseError = 0.49880418 * 16; miouError = 0.66677642 * 1; time = 0.0032s; samplesPerSecond = 4944.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04610740 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.66679806 * 1; time = 0.0032s; samplesPerSecond = 5033.9
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04596606 * 16; pixelwiseError = 0.49832585 * 16; miouError = 0.66679823 * 1; time = 0.0032s; samplesPerSecond = 4969.7
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04600767 * 16; pixelwiseError = 0.49896365 * 16; miouError = 0.66681075 * 1; time = 0.0030s; samplesPerSecond = 5332.5
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04608699 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66680348 * 1; time = 0.0032s; samplesPerSecond = 5018.5
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04595220 * 16; pixelwiseError = 0.49784753 * 16; miouError = 0.66678584 * 1; time = 0.0032s; samplesPerSecond = 4974.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04611240 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66680765 * 1; time = 0.0032s; samplesPerSecond = 5015.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04594596 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66686189 * 1; time = 0.0031s; samplesPerSecond = 5086.8
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04565827 * 16; pixelwiseError = 0.49864474 * 16; miouError = 0.66688412 * 1; time = 0.0029s; samplesPerSecond = 5433.3
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04572549 * 16; pixelwiseError = 0.49936226 * 16; miouError = 0.66691166 * 1; time = 0.0033s; samplesPerSecond = 4916.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04577861 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.66692120 * 1; time = 0.0032s; samplesPerSecond = 4944.1
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04588787 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66695827 * 1; time = 0.0032s; samplesPerSecond = 5013.7
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04579681 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66696721 * 1; time = 0.0030s; samplesPerSecond = 5292.9
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04578758 * 16; pixelwiseError = 0.49968109 * 16; miouError = 0.66698885 * 1; time = 0.0038s; samplesPerSecond = 4246.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04561337 * 16; pixelwiseError = 0.49936223 * 16; miouError = 0.66702259 * 1; time = 0.0036s; samplesPerSecond = 4495.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04561180 * 16; pixelwiseError = 0.49768811 * 16; miouError = 0.66701949 * 1; time = 0.0039s; samplesPerSecond = 4128.2
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04555615 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.66701120 * 1; time = 0.0035s; samplesPerSecond = 4600.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04548022 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.66704601 * 1; time = 0.0035s; samplesPerSecond = 4520.4
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04564869 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.66706741 * 1; time = 0.0035s; samplesPerSecond = 4599.7
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04551123 * 16; pixelwiseError = 0.49713007 * 16; miouError = 0.66705430 * 1; time = 0.0035s; samplesPerSecond = 4522.0
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04540705 * 16; pixelwiseError = 0.49736923 * 16; miouError = 0.66704893 * 1; time = 0.0035s; samplesPerSecond = 4622.6
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04547740 * 16; pixelwiseError = 0.49808672 * 16; miouError = 0.66703588 * 1; time = 0.0036s; samplesPerSecond = 4449.2
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04542789 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.66706908 * 1; time = 0.0045s; samplesPerSecond = 3535.9
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09121689 * 8; pixelwiseError = 0.49936226 * 8; miouError = 0.66708291 * 1; time = 0.0063s; samplesPerSecond = 1262.9
04/13/2017 05:53:28:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66708291 * 1; time = 0.0007s; samplesPerSecond = 0.0
04/13/2017 05:53:28: Finished Epoch[ 2 of 2]: [Training] CE = 0.04668318 * 1000; pixelwiseError = 0.49928443 * 1000; miouError = 0.66708291 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=0.23965s
04/13/2017 05:53:28: Final Results: Minibatch[1-8]: CE = 0.05160971 * 100; pixelwiseError = 0.49910715 * 100; miouError = 0.66589993 * 1
04/13/2017 05:53:28: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05160971 * 100; pixelwiseError = 0.49910715 * 100; miouError = 0.66589993 * 1
04/13/2017 05:53:28: Best epoch per criterion so far: [Validate] CE = 0.051610 (Epoch 2); pixelwiseError = 0.499107 (Epoch 2); miouError = 0.665900 (Epoch 2)
04/13/2017 05:53:28: SGD: Saving checkpoint model '/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train'
04/13/2017 05:53:28: Best epoch for criterion 'CE' is 2 and model /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train copied to /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train_CE
04/13/2017 05:53:28: Best epoch for criterion 'miouError' is 2 and model /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train copied to /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train_miouError
04/13/2017 05:53:28: Best epoch for criterion 'pixelwiseError' is 2 and model /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train copied to /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN8_train_pixelwiseError

04/13/2017 05:53:28: Action "train" complete.


04/13/2017 05:53:28: ##############################################################################
04/13/2017 05:53:28: #                                                                            #
04/13/2017 05:53:28: # ConvertFCN8ToFCN4 command (edit action)                                    #
04/13/2017 05:53:28: #                                                                            #
04/13/2017 05:53:28: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 40 x 40 x 2, Output: 4 x 4 x 2, Kernel: 16 x 16 x 2, Map: 2, Stride: 8 x 8 x 8, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

04/13/2017 05:53:28: Action "edit" complete.


04/13/2017 05:53:28: ##############################################################################
04/13/2017 05:53:28: #                                                                            #
04/13/2017 05:53:28: # TrainFCN4 command (train action)                                           #
04/13/2017 05:53:28: #                                                                            #
04/13/2017 05:53:28: ##############################################################################

04/13/2017 05:53:28: 
Creating virgin network.
Load: Loading model file: /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_initial
Post-processing network...

4 roots:
	ignoreMask = InputValue()
	labels = InputValue()
	predictionFCN8 = Convolution()
	upsampledFCN8.W = LearnableParameter()

Validating network. 62 nodes to process in pass 1.

Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *3]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *3]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *3] -> [14 x 14 x 16 x *3]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *3] -> [7 x 7 x 16 x *3]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *3], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *3], [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *3] -> [4 x 4 x 16 x *3]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *3] -> [4 x 4 x 2 x *3]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [16 x 16 x 2 x 2]

Validating network. 21 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *2] -> [14 x 14 x 16 x *2]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *2] -> [7 x 7 x 16 x *2]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *2], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *2], [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *2] -> [4 x 4 x 16 x *2]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *2] -> [4 x 4 x 2 x *2]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *2] -> [10 x 10 x 2 x *2]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *2] -> [7 x 7 x 2 x *2]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *2], [7 x 7 x 2 x *2] -> [7 x 7 x 2 x *2]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *2] -> [32 x 32 x 2 x *2]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *2]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *2], [28 x 28 x 2 x *2], [28 x 28 x 1 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *2]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *2] -> [784 x 2 x *2]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *2] -> [1 x 2 x *2]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *2] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *2], [28 x 28 x 2 x *2] -> [28 x 28 x 2 x *2]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *2], [28 x 28 x 1 x *2] -> [28 x 28 x 1 x *2]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *2] -> [1 x *2]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *2] -> [1 x *2]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *2], [1 x *2] -> [1 x *2]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

upsampledFCN8: using cuDNN convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using cuDNN convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.

04/13/2017 05:53:29: 
Model has 114 nodes. Using GPU 0.

04/13/2017 05:53:29: Training criterion:   CE = ElementTimes

04/13/2017 05:53:29: Evaluation criteria:
04/13/2017 05:53:29: 	pixelwiseError = ElementTimes
04/13/2017 05:53:29: 	miouError = Minus


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 171 matrices, 107 are shared as 29, and 64 are not shared.

Here are the ones that share memory:
	{ featuresFCN4.x : [14 x 14 x 16 x *2]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *2] (gradient) }
	{ CE.ce_unnorm : [1] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  miouError.iou : [1 x 2]
	  miouError.u : [1 x 2] }
	{ CE.logits.r : [28 x 28 x 1 x *2] (gradient)
	  CE.out_shift : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16] (gradient)
	  featuresFCN4.x : [14 x 14 x 16 x *2] (gradient)
	  featuresFCN4.x._ : [14 x 14 x 16 x *2]
	  miouError.intersectionFlat : [784 x 2 x *2]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *2]
	  miouError.unionFlat : [784 x 2 x *2]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *2]
	  upsampledFCN4 : [32 x 32 x 2 x *2] (gradient) }
	{ CE : [1] (gradient)
	  CE.norm_factor.z : [1]
	  miouError.miou : [1] }
	{ predictionFCN8.W : [2 x 16] (gradient)
	  upsampledFCN8 : [10 x 10 x 2 x *2] }
	{ CE.log_sum.r : [28 x 28 x 1 x *2] (gradient)
	  featuresFCN8 : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b : [4 x 4 x 16 x *2]
	  featuresFCN8.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b : [4 x 4 x 16 x *2]
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  fusionFCN4 : [7 x 7 x 2 x *2] (gradient)
	  miouError.intersectionByClass.r : [1 x 2 x *2]
	  miouError.unionByClass.r : [1 x 2 x *2]
	  pixelwiseError.pixelNorm.z.r : [1 x *2]
	  upsampledFCN8 : [10 x 10 x 2 x *2] (gradient) }
	{ featuresFCN8 : [4 x 4 x 16 x *2]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient) }
	{ cropFCN8 : [7 x 7 x 2 x *2]
	  upsampledFCN8.W : [4 x 4 x 2 x 2] (gradient) }
	{ CE.diff_valid : [28 x 28 x 1 x *2] (gradient)
	  CE.logits_per_class : [28 x 28 x 2 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  miouError.union : [28 x 28 x 2 x *2]
	  out : [28 x 28 x 2 x *2] (gradient)
	  pixelwiseError.acc._ : [28 x 28 x 2 x *2]
	  pixelwiseError.diffs : [28 x 28 x 1 x *2] }
	{ CE.logits_per_class : [28 x 28 x 2 x *2]
	  miouError.intersection : [28 x 28 x 2 x *2]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *2] }
	{ featuresFCN8.b.x : [4 x 4 x 16 x *2]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s : [4 x 4 x 16 x *2] (gradient) }
	{ CE.out_max.r : [28 x 28 x 1 x *2]
	  featuresFCN4 : [7 x 7 x 16 x *2] (gradient)
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient) }
	{ featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *2]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ CE.diff : [28 x 28 x 1 x *2]
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *2] }
	{ featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  featuresFCN8.x.p : [4 x 4 x 16 x *2] }
	{ fusionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN4.W : [2 x 16] (gradient) }
	{ CE.log_sum.r : [28 x 28 x 1 x *2]
	  CE.out_max.r : [28 x 28 x 1 x *2] (gradient)
	  featuresFCN8.x.r : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  predictionFCN4 : [7 x 7 x 2 x *2]
	  predictionFCN8 : [4 x 4 x 2 x *2] (gradient) }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *2] }
	{ CE.diff_valid : [28 x 28 x 1 x *2]
	  CE.logits.r : [28 x 28 x 1 x *2]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *2] }
	{ featuresFCN8.b.x.c : [4 x 4 x 16 x *2]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *2] (gradient) }
	{ featuresFCN4 : [7 x 7 x 16 x *2]
	  featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1] (gradient) }
	{ featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1] (gradient)
	  predictionFCN8 : [4 x 4 x 2 x *2] }
	{ featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient)
	  out : [28 x 28 x 2 x *2] }
	{ featuresFCN4.x._ : [14 x 14 x 16 x *2] (gradient)
	  upsampledFCN4 : [32 x 32 x 2 x *2] }
	{ CE.ce_unnorm : [1]
	  CE.diff : [28 x 28 x 1 x *2] (gradient)
	  cropFCN8 : [7 x 7 x 2 x *2] (gradient)
	  featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1] (gradient)
	  featuresFCN8.b.x : [4 x 4 x 16 x *2] (gradient)
	  featuresFCN8.p : [4 x 4 x 16 x *2]
	  featuresFCN8.p : [4 x 4 x 16 x *2] (gradient) }
	{ CE.out_shift : [28 x 28 x 2 x *2]
	  featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16] (gradient) }

Here are the ones that don't share memory:
	{miouError.norm.z : [1]}
	{miouError.norm : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{pixelwiseError : [1 x *2]}
	{CE : [1]}
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{BS.Constants.One : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{features : [28 x 28 x 1 x *2]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *2]}
	{labels : [28 x 28 x 2 x *2]}
	{predictionFCN8.W : [2 x 16]}
	{miouError : [1]}
	{predictionFCN4.W : [2 x 16]}
	{featuresFCN4.x._.x.c : [14 x 14 x 16 x *2]}
	{pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *2]}
	{featuresFCN8.x.b.x.c : [4 x 4 x 16 x *2]}
	{miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *2]}
	{CE.norm_factor : [1]}
	{pixelwiseError.pixelNorm : [1 x *2]}
	{miouError.i : [1 x 2]}
	{featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *2]}
	{miouError.iouSum.r : [1]}
	{miouError.reciprocalUnion : [1 x 2]}
	{pixelwiseError.errSum.r : [1 x *2]}
	{miouError.outMasked : [28 x 28 x 2 x *2]}
	{miouError.labelMasked : [28 x 28 x 2 x *2]}
	{pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *2]}


04/13/2017 05:53:29: Training 10576 parameters in 21 out of 21 parameter tensors and 57 nodes with gradient:

04/13/2017 05:53:29: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [7 x 7 x 1 x 16]
04/13/2017 05:53:29: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:29: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:29: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W' (LearnableParameter operation) : [3 x 3 x 16 x 16]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.s.arrayOfFunctions[0].W' (LearnableParameter operation) : [1 x 1 x 16 x 16]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].bias' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'featuresFCN8.x.s.arrayOfFunctions[1].scale' (LearnableParameter operation) : [16 x 1]
04/13/2017 05:53:29: 	Node 'predictionFCN4.W' (LearnableParameter operation) : [2 x 16]
04/13/2017 05:53:29: 	Node 'predictionFCN8.W' (LearnableParameter operation) : [2 x 16]
04/13/2017 05:53:29: 	Node 'upsampledFCN8.W' (LearnableParameter operation) : [4 x 4 x 2 x 2]

Initializing dataParallelSGD with FP32 aggregation.
04/13/2017 05:53:29: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

04/13/2017 05:53:29: Starting Epoch 1: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/13/2017 05:53:29: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   1-   1]: CE = 0.05408775 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.69101435 * 1; time = 0.0692s; samplesPerSecond = 231.1
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   2-   2]: CE = 0.05385992 * 16; pixelwiseError = 0.50015950 * 16; miouError = 0.69340897 * 1; time = 0.0380s; samplesPerSecond = 421.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   3-   3]: CE = 0.05385850 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.69396359 * 1; time = 0.0034s; samplesPerSecond = 4761.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   4-   4]: CE = 0.05368470 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.69347245 * 1; time = 0.0035s; samplesPerSecond = 4575.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   5-   5]: CE = 0.05405251 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.69376075 * 1; time = 0.0035s; samplesPerSecond = 4527.2
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   6-   6]: CE = 0.05423248 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69405144 * 1; time = 0.0035s; samplesPerSecond = 4602.9
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   7-   7]: CE = 0.05287198 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.69366407 * 1; time = 0.0033s; samplesPerSecond = 4880.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   8-   8]: CE = 0.05354709 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.69346052 * 1; time = 0.0032s; samplesPerSecond = 5000.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[   9-   9]: CE = 0.05235507 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.69276196 * 1; time = 0.0034s; samplesPerSecond = 4677.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  10-  10]: CE = 0.05295631 * 16; pixelwiseError = 0.49888393 * 16; miouError = 0.69204527 * 1; time = 0.0035s; samplesPerSecond = 4603.4
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  11-  11]: CE = 0.05347540 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.69193125 * 1; time = 0.0034s; samplesPerSecond = 4706.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  12-  12]: CE = 0.05425306 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.69223964 * 1; time = 0.0032s; samplesPerSecond = 5022.1
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  13-  13]: CE = 0.05330452 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.69225311 * 1; time = 0.0034s; samplesPerSecond = 4658.2
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  14-  14]: CE = 0.05264040 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.69169366 * 1; time = 0.0035s; samplesPerSecond = 4614.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  15-  15]: CE = 0.05210487 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.69131744 * 1; time = 0.0035s; samplesPerSecond = 4597.8
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  16-  16]: CE = 0.05206263 * 16; pixelwiseError = 0.50135523 * 16; miouError = 0.69083500 * 1; time = 0.0032s; samplesPerSecond = 4951.4
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  17-  17]: CE = 0.05233765 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.69061160 * 1; time = 0.0033s; samplesPerSecond = 4898.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  18-  18]: CE = 0.05247631 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.69038469 * 1; time = 0.0035s; samplesPerSecond = 4631.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  19-  19]: CE = 0.05215526 * 16; pixelwiseError = 0.49992028 * 16; miouError = 0.68994159 * 1; time = 0.0038s; samplesPerSecond = 4180.6
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  20-  20]: CE = 0.05162365 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.68971562 * 1; time = 0.0034s; samplesPerSecond = 4758.1
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  21-  21]: CE = 0.05161410 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.68927455 * 1; time = 0.0032s; samplesPerSecond = 5037.9
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  22-  22]: CE = 0.05166132 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.68871105 * 1; time = 0.0036s; samplesPerSecond = 4384.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  23-  23]: CE = 0.05194513 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68856919 * 1; time = 0.0037s; samplesPerSecond = 4281.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  24-  24]: CE = 0.05064934 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.68824148 * 1; time = 0.0034s; samplesPerSecond = 4681.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  25-  25]: CE = 0.05066132 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68765390 * 1; time = 0.0032s; samplesPerSecond = 4995.5
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  26-  26]: CE = 0.05086559 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.68713498 * 1; time = 0.0035s; samplesPerSecond = 4631.9
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  27-  27]: CE = 0.05032195 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.68656343 * 1; time = 0.0035s; samplesPerSecond = 4569.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  28-  28]: CE = 0.05003523 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.68584514 * 1; time = 0.0034s; samplesPerSecond = 4651.1
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  29-  29]: CE = 0.05032285 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.68524969 * 1; time = 0.0032s; samplesPerSecond = 4984.1
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  30-  30]: CE = 0.05034604 * 16; pixelwiseError = 0.50119579 * 16; miouError = 0.68489504 * 1; time = 0.0033s; samplesPerSecond = 4867.6
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  31-  31]: CE = 0.05042289 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.68453604 * 1; time = 0.0034s; samplesPerSecond = 4638.5
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  32-  32]: CE = 0.04997972 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.68396080 * 1; time = 0.0035s; samplesPerSecond = 4620.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  33-  33]: CE = 0.04988774 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68333328 * 1; time = 0.0034s; samplesPerSecond = 4772.2
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  34-  34]: CE = 0.04989060 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.68268132 * 1; time = 0.0032s; samplesPerSecond = 5017.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  35-  35]: CE = 0.04950384 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.68214953 * 1; time = 0.0034s; samplesPerSecond = 4661.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  36-  36]: CE = 0.04935883 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.68155694 * 1; time = 0.0034s; samplesPerSecond = 4681.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  37-  37]: CE = 0.04955866 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.68087274 * 1; time = 0.0034s; samplesPerSecond = 4657.5
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  38-  38]: CE = 0.04900101 * 16; pixelwiseError = 0.50047827 * 16; miouError = 0.68023235 * 1; time = 0.0032s; samplesPerSecond = 5042.8
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  39-  39]: CE = 0.04891431 * 16; pixelwiseError = 0.50127548 * 16; miouError = 0.67955440 * 1; time = 0.0034s; samplesPerSecond = 4726.8
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  40-  40]: CE = 0.04941816 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67893600 * 1; time = 0.0034s; samplesPerSecond = 4688.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  41-  41]: CE = 0.04928011 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67836356 * 1; time = 0.0041s; samplesPerSecond = 3910.7
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  42-  42]: CE = 0.04905730 * 16; pixelwiseError = 0.49856505 * 16; miouError = 0.67784262 * 1; time = 0.0042s; samplesPerSecond = 3841.6
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  43-  43]: CE = 0.04904880 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67723453 * 1; time = 0.0038s; samplesPerSecond = 4226.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  44-  44]: CE = 0.04888847 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67673409 * 1; time = 0.0037s; samplesPerSecond = 4339.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  45-  45]: CE = 0.04921469 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67626268 * 1; time = 0.0038s; samplesPerSecond = 4176.5
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  46-  46]: CE = 0.04886924 * 16; pixelwiseError = 0.49760839 * 16; miouError = 0.67585605 * 1; time = 0.0041s; samplesPerSecond = 3909.9
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  47-  47]: CE = 0.04896331 * 16; pixelwiseError = 0.50007969 * 16; miouError = 0.67539227 * 1; time = 0.0043s; samplesPerSecond = 3683.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  48-  48]: CE = 0.04925616 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67490512 * 1; time = 0.0037s; samplesPerSecond = 4316.1
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  49-  49]: CE = 0.04920718 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67444623 * 1; time = 0.0032s; samplesPerSecond = 4959.5
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  50-  50]: CE = 0.04889720 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67408377 * 1; time = 0.0033s; samplesPerSecond = 4894.5
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  51-  51]: CE = 0.04893079 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67369848 * 1; time = 0.0034s; samplesPerSecond = 4675.2
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  52-  52]: CE = 0.04907062 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.67328125 * 1; time = 0.0034s; samplesPerSecond = 4664.4
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  53-  53]: CE = 0.04876297 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67292649 * 1; time = 0.0034s; samplesPerSecond = 4699.8
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  54-  54]: CE = 0.04880439 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67260420 * 1; time = 0.0032s; samplesPerSecond = 5020.6
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  55-  55]: CE = 0.04883906 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.67225778 * 1; time = 0.0034s; samplesPerSecond = 4653.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  56-  56]: CE = 0.04879902 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67195672 * 1; time = 0.0046s; samplesPerSecond = 3452.6
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  57-  57]: CE = 0.04886764 * 16; pixelwiseError = 0.50039864 * 16; miouError = 0.67162603 * 1; time = 0.0036s; samplesPerSecond = 4426.5
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  58-  58]: CE = 0.04896065 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67133880 * 1; time = 0.0032s; samplesPerSecond = 4966.4
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  59-  59]: CE = 0.04855736 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67108464 * 1; time = 0.0035s; samplesPerSecond = 4620.3
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  60-  60]: CE = 0.04910399 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67081875 * 1; time = 0.0034s; samplesPerSecond = 4651.0
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  61-  61]: CE = 0.04917118 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67052615 * 1; time = 0.0035s; samplesPerSecond = 4623.4
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  62-  62]: CE = 0.04896244 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67026734 * 1; time = 0.0032s; samplesPerSecond = 5031.9
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  63-  63]: CE = 0.09795211 * 8; pixelwiseError = 0.50159436 * 8; miouError = 0.67015713 * 1; time = 0.0055s; samplesPerSecond = 1465.2
04/13/2017 05:53:29:  Epoch[ 1 of 2]-Minibatch[  64-  64]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.67015713 * 1; time = 0.0008s; samplesPerSecond = 0.0
04/13/2017 05:53:29: Finished Epoch[ 1 of 2]: [Training] CE = 0.05108460 * 1000; pixelwiseError = 0.49989668 * 1000; miouError = 0.67015719 * 1; totalSamplesSeen = 1000; learningRatePerSample = 0.0099999998; epochTime=0.332362s
04/13/2017 05:53:29: Final Results: Minibatch[1-8]: CE = 0.05615914 * 100; pixelwiseError = 0.50025512 * 100; miouError = 0.67410249 * 1
04/13/2017 05:53:29: Finished Epoch[ 1 of 2]: [Validate] CE = 0.05615914 * 100; pixelwiseError = 0.50025512 * 100; miouError = 0.67410249 * 1
04/13/2017 05:53:29: Best epoch per criterion so far: [Validate] CE = 0.056159 (Epoch 1); pixelwiseError = 0.500255 (Epoch 1); miouError = 0.674102 (Epoch 1)
04/13/2017 05:53:29: SGD: Saving checkpoint model '/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train.1'

04/13/2017 05:53:29: Starting Epoch 2: learning rate per sample = 0.010000  effective momentum = 0.986917  momentum as time constant = 1215.0 samples

04/13/2017 05:53:29: Starting minibatch loop, DataParallelSGD training (myRank = 0, numNodes = 1, numGradientBits = 32), distributed reading is ENABLED.
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   1-   1, 0.00%]: CE = 0.04874099 * 16; pixelwiseError = 0.50031888 * 16; miouError = 0.67050052 * 1; time = 0.0038s; samplesPerSecond = 4181.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   2-   2, 0.00%]: CE = 0.04858384 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.67125404 * 1; time = 0.0039s; samplesPerSecond = 4114.9
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   3-   3, 0.00%]: CE = 0.04862280 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67129683 * 1; time = 0.0039s; samplesPerSecond = 4061.1
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   4-   4, 0.00%]: CE = 0.04852143 * 16; pixelwiseError = 0.50023913 * 16; miouError = 0.67108727 * 1; time = 0.0040s; samplesPerSecond = 4027.9
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   5-   5, 0.00%]: CE = 0.04924892 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67148143 * 1; time = 0.0039s; samplesPerSecond = 4108.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   6-   6, 0.00%]: CE = 0.04842562 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67124271 * 1; time = 0.0034s; samplesPerSecond = 4740.2
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   7-   7, 0.00%]: CE = 0.04870998 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67147034 * 1; time = 0.0037s; samplesPerSecond = 4328.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   8-   8, 0.00%]: CE = 0.04856205 * 16; pixelwiseError = 0.50103635 * 16; miouError = 0.67165995 * 1; time = 0.0041s; samplesPerSecond = 3881.5
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[   9-   9, 0.00%]: CE = 0.04851801 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67176247 * 1; time = 0.0035s; samplesPerSecond = 4597.6
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  10-  10, 0.00%]: CE = 0.04858113 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67185837 * 1; time = 0.0032s; samplesPerSecond = 4989.6
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  11-  11, 0.00%]: CE = 0.04842683 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67187929 * 1; time = 0.0033s; samplesPerSecond = 4825.8
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  12-  12, 0.00%]: CE = 0.04870834 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67207670 * 1; time = 0.0041s; samplesPerSecond = 3904.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  13-  13, 0.00%]: CE = 0.04835904 * 16; pixelwiseError = 0.50071746 * 16; miouError = 0.67225111 * 1; time = 0.0041s; samplesPerSecond = 3886.0
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  14-  14, 0.00%]: CE = 0.04857202 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67253977 * 1; time = 0.0038s; samplesPerSecond = 4246.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  15-  15, 0.00%]: CE = 0.04875072 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67262214 * 1; time = 0.0035s; samplesPerSecond = 4635.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  16-  16, 0.00%]: CE = 0.04838068 * 16; pixelwiseError = 0.50055802 * 16; miouError = 0.67275602 * 1; time = 0.0034s; samplesPerSecond = 4746.0
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  17-  17, 0.00%]: CE = 0.04791684 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67270046 * 1; time = 0.0055s; samplesPerSecond = 2913.6
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  18-  18, 0.00%]: CE = 0.04792583 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67268336 * 1; time = 0.0038s; samplesPerSecond = 4218.9
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  19-  19, 0.00%]: CE = 0.04791663 * 16; pixelwiseError = 0.50000000 * 16; miouError = 0.67263252 * 1; time = 0.0034s; samplesPerSecond = 4740.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  20-  20, 0.00%]: CE = 0.04778190 * 16; pixelwiseError = 0.50047833 * 16; miouError = 0.67264903 * 1; time = 0.0035s; samplesPerSecond = 4626.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  21-  21, 0.00%]: CE = 0.04807526 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67282283 * 1; time = 0.0035s; samplesPerSecond = 4617.1
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  22-  22, 0.00%]: CE = 0.04770991 * 16; pixelwiseError = 0.50023919 * 16; miouError = 0.67289817 * 1; time = 0.0032s; samplesPerSecond = 4992.9
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  23-  23, 0.00%]: CE = 0.04764010 * 16; pixelwiseError = 0.50111610 * 16; miouError = 0.67300618 * 1; time = 0.0036s; samplesPerSecond = 4397.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  24-  24, 0.00%]: CE = 0.04776153 * 16; pixelwiseError = 0.50159442 * 16; miouError = 0.67308682 * 1; time = 0.0035s; samplesPerSecond = 4592.6
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  25-  25, 0.00%]: CE = 0.04778301 * 16; pixelwiseError = 0.50127554 * 16; miouError = 0.67318898 * 1; time = 0.0035s; samplesPerSecond = 4610.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  26-  26, 0.00%]: CE = 0.04750778 * 16; pixelwiseError = 0.50063777 * 16; miouError = 0.67319667 * 1; time = 0.0033s; samplesPerSecond = 4855.0
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  27-  27, 0.00%]: CE = 0.04693048 * 16; pixelwiseError = 0.50087690 * 16; miouError = 0.67312050 * 1; time = 0.0033s; samplesPerSecond = 4873.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  28-  28, 0.00%]: CE = 0.04714453 * 16; pixelwiseError = 0.50095665 * 16; miouError = 0.67310643 * 1; time = 0.0035s; samplesPerSecond = 4623.5
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  29-  29, 0.00%]: CE = 0.04725985 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.67307043 * 1; time = 0.0035s; samplesPerSecond = 4602.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  30-  30, 0.00%]: CE = 0.04727471 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67294729 * 1; time = 0.0035s; samplesPerSecond = 4634.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  31-  31, 0.00%]: CE = 0.04711290 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.67284262 * 1; time = 0.0032s; samplesPerSecond = 4997.1
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  32-  32, 0.00%]: CE = 0.04695430 * 16; pixelwiseError = 0.49944198 * 16; miouError = 0.67272544 * 1; time = 0.0034s; samplesPerSecond = 4650.5
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  33-  33, 0.00%]: CE = 0.04690143 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.67259353 * 1; time = 0.0035s; samplesPerSecond = 4632.5
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  34-  34, 0.00%]: CE = 0.04688374 * 16; pixelwiseError = 0.50111604 * 16; miouError = 0.67254496 * 1; time = 0.0035s; samplesPerSecond = 4635.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  35-  35, 0.00%]: CE = 0.04653953 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67239618 * 1; time = 0.0032s; samplesPerSecond = 4971.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  36-  36, 0.00%]: CE = 0.04644160 * 16; pixelwiseError = 0.49832588 * 16; miouError = 0.67217225 * 1; time = 0.0033s; samplesPerSecond = 4794.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  37-  37, 0.00%]: CE = 0.04687496 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67208529 * 1; time = 0.0035s; samplesPerSecond = 4623.2
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  38-  38, 0.00%]: CE = 0.04662452 * 16; pixelwiseError = 0.49920282 * 16; miouError = 0.67191339 * 1; time = 0.0035s; samplesPerSecond = 4577.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  39-  39, 0.00%]: CE = 0.04632363 * 16; pixelwiseError = 0.49848530 * 16; miouError = 0.67169821 * 1; time = 0.0034s; samplesPerSecond = 4713.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  40-  40, 0.00%]: CE = 0.04650136 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.67155457 * 1; time = 0.0032s; samplesPerSecond = 4987.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  41-  41, 0.00%]: CE = 0.04661700 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.67142862 * 1; time = 0.0034s; samplesPerSecond = 4638.0
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  42-  42, 0.00%]: CE = 0.04636487 * 16; pixelwiseError = 0.49904335 * 16; miouError = 0.67122734 * 1; time = 0.0035s; samplesPerSecond = 4633.8
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  43-  43, 0.00%]: CE = 0.04632146 * 16; pixelwiseError = 0.49872446 * 16; miouError = 0.67101312 * 1; time = 0.0035s; samplesPerSecond = 4627.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  44-  44, 0.00%]: CE = 0.04622528 * 16; pixelwiseError = 0.49824616 * 16; miouError = 0.67080224 * 1; time = 0.0032s; samplesPerSecond = 5014.8
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  45-  45, 0.00%]: CE = 0.04666244 * 16; pixelwiseError = 0.49952167 * 16; miouError = 0.67064977 * 1; time = 0.0034s; samplesPerSecond = 4687.8
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  46-  46, 0.00%]: CE = 0.04639157 * 16; pixelwiseError = 0.50007975 * 16; miouError = 0.67052317 * 1; time = 0.0035s; samplesPerSecond = 4572.9
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  47-  47, 0.00%]: CE = 0.04653845 * 16; pixelwiseError = 0.49944195 * 16; miouError = 0.67040622 * 1; time = 0.0035s; samplesPerSecond = 4610.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  48-  48, 0.00%]: CE = 0.04647619 * 16; pixelwiseError = 0.49816644 * 16; miouError = 0.67023808 * 1; time = 0.0033s; samplesPerSecond = 4915.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  49-  49, 0.00%]: CE = 0.04665386 * 16; pixelwiseError = 0.49896362 * 16; miouError = 0.67009926 * 1; time = 0.0033s; samplesPerSecond = 4896.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  50-  50, 0.00%]: CE = 0.04646945 * 16; pixelwiseError = 0.49912307 * 16; miouError = 0.66996235 * 1; time = 0.0035s; samplesPerSecond = 4598.1
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  51-  51, 0.00%]: CE = 0.04623291 * 16; pixelwiseError = 0.50039858 * 16; miouError = 0.66985059 * 1; time = 0.0035s; samplesPerSecond = 4628.0
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  52-  52, 0.00%]: CE = 0.04638718 * 16; pixelwiseError = 0.49960139 * 16; miouError = 0.66968501 * 1; time = 0.0034s; samplesPerSecond = 4680.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  53-  53, 0.00%]: CE = 0.04618829 * 16; pixelwiseError = 0.49984056 * 16; miouError = 0.66952431 * 1; time = 0.0032s; samplesPerSecond = 4961.7
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  54-  54, 0.00%]: CE = 0.04628293 * 16; pixelwiseError = 0.49976084 * 16; miouError = 0.66939408 * 1; time = 0.0034s; samplesPerSecond = 4655.2
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  55-  55, 0.00%]: CE = 0.04640334 * 16; pixelwiseError = 0.49888390 * 16; miouError = 0.66923892 * 1; time = 0.0035s; samplesPerSecond = 4631.1
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  56-  56, 0.00%]: CE = 0.04634196 * 16; pixelwiseError = 0.49920279 * 16; miouError = 0.66905266 * 1; time = 0.0034s; samplesPerSecond = 4647.2
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  57-  57, 0.00%]: CE = 0.04644903 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66891956 * 1; time = 0.0032s; samplesPerSecond = 4982.3
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  58-  58, 0.00%]: CE = 0.04599605 * 16; pixelwiseError = 0.50015944 * 16; miouError = 0.66880375 * 1; time = 0.0033s; samplesPerSecond = 4818.4
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  59-  59, 0.00%]: CE = 0.04626735 * 16; pixelwiseError = 0.49928251 * 16; miouError = 0.66868013 * 1; time = 0.0034s; samplesPerSecond = 4639.8
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  60-  60, 0.00%]: CE = 0.04629908 * 16; pixelwiseError = 0.49880418 * 16; miouError = 0.66854382 * 1; time = 0.0035s; samplesPerSecond = 4601.2
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  61-  61, 0.00%]: CE = 0.04630848 * 16; pixelwiseError = 0.49888390 * 16; miouError = 0.66838825 * 1; time = 0.0034s; samplesPerSecond = 4730.8
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  62-  62, 0.00%]: CE = 0.04616680 * 16; pixelwiseError = 0.49968112 * 16; miouError = 0.66827524 * 1; time = 0.0036s; samplesPerSecond = 4490.9
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  63-  63, 0.00%]: CE = 0.09348119 * 8; pixelwiseError = 0.50015944 * 8; miouError = 0.66821980 * 1; time = 0.0051s; samplesPerSecond = 1579.5
04/13/2017 05:53:29:  Epoch[ 2 of 2]-Minibatch[  64-  64, 0.00%]: CE = 0.00000000 * 0; pixelwiseError = 0.00000000 * 0; miouError = 0.66821980 * 1; time = 0.0006s; samplesPerSecond = 0.0
04/13/2017 05:53:29: Finished Epoch[ 2 of 2]: [Training] CE = 0.04765253 * 1000; pixelwiseError = 0.49989540 * 1000; miouError = 0.66821980 * 1; totalSamplesSeen = 2000; learningRatePerSample = 0.0099999998; epochTime=0.230852s
04/13/2017 05:53:29: Final Results: Minibatch[1-8]: CE = 0.05273981 * 100; pixelwiseError = 0.50051021 * 100; miouError = 0.66819537 * 1
04/13/2017 05:53:29: Finished Epoch[ 2 of 2]: [Validate] CE = 0.05273981 * 100; pixelwiseError = 0.50051021 * 100; miouError = 0.66819537 * 1
04/13/2017 05:53:29: Best epoch per criterion so far: [Validate] CE = 0.052740 (Epoch 2); pixelwiseError = 0.500255 (Epoch 1); miouError = 0.668195 (Epoch 2)
04/13/2017 05:53:29: SGD: Saving checkpoint model '/tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train'
04/13/2017 05:53:29: Best epoch for criterion 'CE' is 2 and model /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train copied to /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train_CE
04/13/2017 05:53:29: Best epoch for criterion 'miouError' is 2 and model /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train copied to /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train_miouError
04/13/2017 05:53:29: Best epoch for criterion 'pixelwiseError' is 1 and model /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train.1 copied to /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_train_pixelwiseError

04/13/2017 05:53:29: Action "train" complete.


04/13/2017 05:53:29: ##############################################################################
04/13/2017 05:53:29: #                                                                            #
04/13/2017 05:53:29: # PrepareFCN4ForTest command (edit action)                                   #
04/13/2017 05:53:29: #                                                                            #
04/13/2017 05:53:29: ##############################################################################

featuresFCN4.x._.x.c: using GEMM convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using GEMM convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using GEMM convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using GEMM convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using GEMM convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using GEMM convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.

04/13/2017 05:53:29: Action "edit" complete.


04/13/2017 05:53:29: ##############################################################################
04/13/2017 05:53:29: #                                                                            #
04/13/2017 05:53:29: # TestFCN4 command (test action)                                             #
04/13/2017 05:53:29: #                                                                            #
04/13/2017 05:53:29: ##############################################################################

Load: Loading model file: /tmp/cntk-test-20170413055247.385331/Image_FCN@release_gpu/Models/FCN4_test
Post-processing network...

4 roots:
	CE = ElementTimes()
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 114 nodes to process in pass 1.

Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *6] -> [14 x 14 x 16 x *6]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *6] -> [7 x 7 x 16 x *6]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *6], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *6], [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *6] -> [4 x 4 x 16 x *6]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *6] -> [4 x 4 x 2 x *6]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *6] -> [10 x 10 x 2 x *6]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *6] -> [7 x 7 x 2 x *6]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *6], [7 x 7 x 2 x *6] -> [7 x 7 x 2 x *6]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *6] -> [32 x 32 x 2 x *6]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *6]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *6], [28 x 28 x 2 x *6], [28 x 28 x 1 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.out_max.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.out_shift = Minus (out, CE.out_max.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.log_sum.r = ReduceElements (CE.out_shift) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.logits_per_class = ElementTimes (labels, CE.out_shift) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> CE.logits.r = ReduceElements (CE.logits_per_class) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.diff = Minus (CE.log_sum.r, CE.logits.r) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *6]
Validating --> CE.diff_valid = ElementTimes (CE.diff, ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> CE.ce_unnorm = SumElements (CE.diff_valid) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor.z = SumElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1]
Validating --> CE.norm_factor = Reciprocal (CE.norm_factor.z) : [1] -> [1]
Validating --> CE = ElementTimes (CE.ce_unnorm, CE.norm_factor) : [1], [1] -> [1]
Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *6] -> [784 x 2 x *6]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *6] -> [1 x 2 x *6]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *6] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *6], [28 x 28 x 2 x *6] -> [28 x 28 x 2 x *6]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *6], [28 x 28 x 1 x *6] -> [28 x 28 x 1 x *6]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *6] -> [1 x *6]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *6] -> [1 x *6]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *6], [1 x *6] -> [1 x *6]

Validating network. 68 nodes to process in pass 2.


Validating network, final pass.

featuresFCN4.x._.x.c: using cuDNN convolution engine for geometry: Input: 28 x 28 x 1, Output: 14 x 14 x 16, Kernel: 7 x 7 x 1, Map: 16, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN4: using cuDNN convolution engine for geometry: Input: 14 x 14 x 16, Output: 7 x 7 x 16, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
featuresFCN8.x.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.x.s.x.c: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 4 x 4 x 16, Kernel: 1 x 1 x 16, Map: 16, Stride: 2 x 2 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x._.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
featuresFCN8.b.x.c: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 16, Kernel: 3 x 3 x 16, Map: 16, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (1, 1, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
Using CNTK batch normalization engine.
predictionFCN8: using cuDNN convolution engine for geometry: Input: 4 x 4 x 16, Output: 4 x 4 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN8: using cuDNN convolution engine for geometry: Input: 10 x 10 x 2, Output: 4 x 4 x 2, Kernel: 4 x 4 x 2, Map: 2, Stride: 2 x 2 x 2, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
predictionFCN4: using cuDNN convolution engine for geometry: Input: 7 x 7 x 16, Output: 7 x 7 x 2, Kernel: 1 x 1 x 16, Map: 1 x 1 x 2, Stride: 1 x 1 x 16, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.
upsampledFCN4: using cuDNN convolution engine for geometry: Input: 32 x 32 x 2, Output: 7 x 7 x 2, Kernel: 8 x 8 x 2, Map: 2, Stride: 4 x 4 x 4, Sharing: (1, 1, 1), AutoPad: (0, 0, 0), LowerPad: 0 x 0 x 0, UpperPad: 0 x 0 x 0.



Post-processing network complete.


Post-processing network...

3 roots:
	miouError = Minus()
	out = Crop()
	pixelwiseError = ElementTimes()

Validating network. 103 nodes to process in pass 1.

Validating --> BS.Constants.One = LearnableParameter() :  -> [1]
Validating --> upsampledFCN4.W = LearnableParameter() :  -> [8 x 8 x 2 x 2]
Validating --> upsampledFCN8.W = LearnableParameter() :  -> [4 x 4 x 2 x 2]
Validating --> predictionFCN8.W = LearnableParameter() :  -> [2 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [3 x 3 x 16 x 16]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W = LearnableParameter() :  -> [7 x 7 x 1 x 16]
Validating --> features = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> featuresFCN4.x._.x.c = Convolution (featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, features) : [7 x 7 x 1 x 16], [28 x 28 x 1 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN4.x._ = BatchNormalization (featuresFCN4.x._.x.c, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [14 x 14 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4.x = RectifiedLinear (featuresFCN4.x._) : [14 x 14 x 16 x *5] -> [14 x 14 x 16 x *5]
Validating --> featuresFCN4 = Pooling (featuresFCN4.x) : [14 x 14 x 16 x *5] -> [7 x 7 x 16 x *5]
Validating --> featuresFCN8.x.b.x._.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN4) : [3 x 3 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b.x._ = BatchNormalization (featuresFCN8.x.b.x._.x.c, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x = RectifiedLinear (featuresFCN8.x.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.x.c = Convolution (featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.x.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.b = BatchNormalization (featuresFCN8.x.b.x.c, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[0].W = LearnableParameter() :  -> [1 x 1 x 16 x 16]
Validating --> featuresFCN8.x.s.x.c = Convolution (featuresFCN8.x.s.arrayOfFunctions[0].W, featuresFCN4) : [1 x 1 x 16 x 16], [7 x 7 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.x.s.arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.x.s = BatchNormalization (featuresFCN8.x.s.x.c, featuresFCN8.x.s.arrayOfFunctions[1].scale, featuresFCN8.x.s.arrayOfFunctions[1].bias, featuresFCN8.x.s.arrayOfFunctions[1].runMean, featuresFCN8.x.s.arrayOfFunctions[1].runVariance, featuresFCN8.x.s.arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.p = Plus (featuresFCN8.x.b, featuresFCN8.x.s) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.x.r = RectifiedLinear (featuresFCN8.x.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x._.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W, featuresFCN8.x.r) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b.x._ = BatchNormalization (featuresFCN8.b.x._.x.c, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x = RectifiedLinear (featuresFCN8.b.x._) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.x.c = Convolution (featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W, featuresFCN8.b.x) : [3 x 3 x 16 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance = LearnableParameter() :  -> [16 x 1]
Validating --> featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount = LearnableParameter() :  -> [1]
Validating --> featuresFCN8.b = BatchNormalization (featuresFCN8.b.x.c, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance, featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount) : [4 x 4 x 16 x *5], [16 x 1], [16 x 1], [16 x 1], [16 x 1], [1] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8.p = Plus (featuresFCN8.b, featuresFCN8.x.r) : [4 x 4 x 16 x *5], [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> featuresFCN8 = RectifiedLinear (featuresFCN8.p) : [4 x 4 x 16 x *5] -> [4 x 4 x 16 x *5]
Validating --> predictionFCN8 = Convolution (predictionFCN8.W, featuresFCN8) : [2 x 16], [4 x 4 x 16 x *5] -> [4 x 4 x 2 x *5]
Validating --> upsampledFCN8 = Convolution (upsampledFCN8.W, predictionFCN8) : [4 x 4 x 2 x 2], [4 x 4 x 2 x *5] -> [10 x 10 x 2 x *5]
Validating --> predictionFCN4.W = LearnableParameter() :  -> [2 x 16]
Validating --> predictionFCN4 = Convolution (predictionFCN4.W, featuresFCN4) : [2 x 16], [7 x 7 x 16 x *5] -> [7 x 7 x 2 x *5]
Validating --> cropFCN8 = Crop (upsampledFCN8, predictionFCN4) : [10 x 10 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> fusionFCN4 = Plus (cropFCN8, predictionFCN4) : [7 x 7 x 2 x *5], [7 x 7 x 2 x *5] -> [7 x 7 x 2 x *5]
Validating --> upsampledFCN4 = Convolution (upsampledFCN4.W, fusionFCN4) : [8 x 8 x 2 x 2], [7 x 7 x 2 x *5] -> [32 x 32 x 2 x *5]
Validating --> labels = InputValue() :  -> [28 x 28 x 2 x *5]
Validating --> out = Crop (upsampledFCN4, labels, features, labels) : [32 x 32 x 2 x *5], [28 x 28 x 2 x *5], [28 x 28 x 1 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> miouError.outHardmax.isMax = Equal (out, miouError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> ignoreMask = InputValue() :  -> [28 x 28 x 1 x *5]
Validating --> miouError.outMasked = ElementTimes (miouError.outHardmax.isMax, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.labelMasked = ElementTimes (labels, ignoreMask) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersection = ElementTimes (miouError.outMasked, miouError.labelMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.intersectionFlat = Reshape (miouError.intersection) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.intersectionByClass.r = ReduceElements (miouError.intersectionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.i = EpochAccumulator (miouError.intersectionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.union.MinusArgs[0] = Plus (miouError.labelMasked, miouError.outMasked) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.union = Minus (miouError.union.MinusArgs[0], miouError.intersection) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> miouError.unionFlat = Reshape (miouError.union) : [28 x 28 x 2 x *5] -> [784 x 2 x *5]
Validating --> miouError.unionByClass.r = ReduceElements (miouError.unionFlat) : [784 x 2 x *5] -> [1 x 2 x *5]
Validating --> miouError.u = EpochAccumulator (miouError.unionByClass.r) : [1 x 2 x *5] -> [1 x 2]
Validating --> miouError.reciprocalUnion.z.PlusArgs[1] = LearnableParameter() :  -> [1]
Validating --> miouError.reciprocalUnion.z = Plus (miouError.u, miouError.reciprocalUnion.z.PlusArgs[1]) : [1 x 2], [1] -> [1 x 2]
Validating --> miouError.reciprocalUnion = Reciprocal (miouError.reciprocalUnion.z) : [1 x 2] -> [1 x 2]
Validating --> miouError.iou = ElementTimes (miouError.i, miouError.reciprocalUnion) : [1 x 2], [1 x 2] -> [1 x 2]
Validating --> miouError.iouSum.r = ReduceElements (miouError.iou) : [1 x 2] -> [1]
Validating --> miouError.norm.z = LearnableParameter() :  -> [1]
Validating --> miouError.norm = Reciprocal (miouError.norm.z) : [1] -> [1]
Validating --> miouError.miou = ElementTimes (miouError.iouSum.r, miouError.norm) : [1], [1] -> [1]
Validating --> miouError = Minus (BS.Constants.One, miouError.miou) : [1], [1] -> [1]
Validating --> pixelwiseError.outHardmax.maxVals.r = ReduceElements (out) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.outHardmax.isMax = Equal (out, pixelwiseError.outHardmax.maxVals.r) : [28 x 28 x 2 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc._ = ElementTimes (labels, pixelwiseError.outHardmax.isMax) : [28 x 28 x 2 x *5], [28 x 28 x 2 x *5] -> [28 x 28 x 2 x *5]
Validating --> pixelwiseError.acc.r = ReduceElements (pixelwiseError.acc._) : [28 x 28 x 2 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs.ElementTimesArgs[0] = Minus (BS.Constants.One, pixelwiseError.acc.r) : [1], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.diffs = ElementTimes (pixelwiseError.diffs.ElementTimesArgs[0], ignoreMask) : [28 x 28 x 1 x *5], [28 x 28 x 1 x *5] -> [28 x 28 x 1 x *5]
Validating --> pixelwiseError.errSum.r = ReduceElements (pixelwiseError.diffs) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm.z.r = ReduceElements (ignoreMask) : [28 x 28 x 1 x *5] -> [1 x *5]
Validating --> pixelwiseError.pixelNorm = Reciprocal (pixelwiseError.pixelNorm.z.r) : [1 x *5] -> [1 x *5]
Validating --> pixelwiseError = ElementTimes (pixelwiseError.errSum.r, pixelwiseError.pixelNorm) : [1 x *5], [1 x *5] -> [1 x *5]

Validating network. 56 nodes to process in pass 2.


Validating network, final pass.




Post-processing network complete.

evalNodeNames are not specified, using all the default evalnodes and training criterion nodes.


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 103 matrices, 54 are shared as 7, and 49 are not shared.

Here are the ones that share memory:
	{ featuresFCN8 : [4 x 4 x 16 x *5]
	  featuresFCN8.b : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x._.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._.x.c : [4 x 4 x 16 x *5]
	  out : [28 x 28 x 2 x *5]
	  pixelwiseError.acc._ : [28 x 28 x 2 x *5]
	  pixelwiseError.diffs.ElementTimesArgs[0] : [28 x 28 x 1 x *5]
	  pixelwiseError.pixelNorm : [1 x *5]
	  upsampledFCN8 : [10 x 10 x 2 x *5] }
	{ cropFCN8 : [7 x 7 x 2 x *5]
	  featuresFCN8.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x._ : [4 x 4 x 16 x *5]
	  featuresFCN8.x.b.x.c : [4 x 4 x 16 x *5]
	  featuresFCN8.x.p : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s.x.c : [4 x 4 x 16 x *5]
	  miouError.intersection : [28 x 28 x 2 x *5]
	  pixelwiseError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  predictionFCN8 : [4 x 4 x 2 x *5] }
	{ featuresFCN4.x._ : [14 x 14 x 16 x *5]
	  featuresFCN8.x.r : [4 x 4 x 16 x *5]
	  featuresFCN8.x.s : [4 x 4 x 16 x *5]
	  miouError.outMasked : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion : [1 x 2]
	  miouError.u : [1 x 2]
	  miouError.union : [28 x 28 x 2 x *5]
	  predictionFCN4 : [7 x 7 x 2 x *5]
	  upsampledFCN4 : [32 x 32 x 2 x *5] }
	{ featuresFCN4.x : [14 x 14 x 16 x *5]
	  featuresFCN4.x._.x.c : [14 x 14 x 16 x *5]
	  miouError.iou : [1 x 2]
	  miouError.labelMasked : [28 x 28 x 2 x *5]
	  miouError.miou : [1]
	  miouError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  miouError.reciprocalUnion.z : [1 x 2] }
	{ featuresFCN4 : [7 x 7 x 16 x *5]
	  fusionFCN4 : [7 x 7 x 2 x *5]
	  miouError.intersectionFlat : [784 x 2 x *5]
	  miouError.outHardmax.maxVals.r : [28 x 28 x 1 x *5]
	  miouError.union.MinusArgs[0] : [28 x 28 x 2 x *5]
	  miouError.unionFlat : [784 x 2 x *5]
	  pixelwiseError.acc.r : [28 x 28 x 1 x *5]
	  pixelwiseError.diffs : [28 x 28 x 1 x *5]
	  pixelwiseError.outHardmax.isMax : [28 x 28 x 2 x *5]
	  pixelwiseError.pixelNorm.z.r : [1 x *5] }
	{ miouError.intersectionByClass.r : [1 x 2 x *5]
	  miouError.unionByClass.r : [1 x 2 x *5]
	  pixelwiseError.errSum.r : [1 x *5] }
	{ miouError.i : [1 x 2]
	  miouError.iouSum.r : [1] }

Here are the ones that don't share memory:
	{pixelwiseError : [1 x *5]}
	{miouError : [1]}
	{miouError.norm : [1]}
	{BS.Constants.One : [1]}
	{features : [28 x 28 x 1 x *5]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [7 x 7 x 1 x 16]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN4.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[0].arrayOfFunctions[0].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[0].W : [3 x 3 x 16 x 16]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.b.arrayOfFunctions[1].arrayOfFunctions[1].scale : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[0].W : [1 x 1 x 16 x 16]}
	{featuresFCN8.x.s.arrayOfFunctions[1].bias : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runCount : [1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runMean : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].runVariance : [16 x 1]}
	{featuresFCN8.x.s.arrayOfFunctions[1].scale : [16 x 1]}
	{ignoreMask : [28 x 28 x 1 x *5]}
	{labels : [28 x 28 x 2 x *5]}
	{miouError.norm.z : [1]}
	{miouError.reciprocalUnion.z.PlusArgs[1] : [1]}
	{predictionFCN4.W : [2 x 16]}
	{predictionFCN8.W : [2 x 16]}
	{upsampledFCN4.W : [8 x 8 x 2 x 2]}
	{upsampledFCN8.W : [4 x 4 x 2 x 2]}

04/13/2017 05:53:29: Minibatch[1-8]: pixelwiseError = 0.50051021 * 100; miouError = 0.66819537 * 1
04/13/2017 05:53:29: Final Results: Minibatch[1-8]: pixelwiseError = 0.50051021 * 100; miouError = 0.66819543 * 1

04/13/2017 05:53:29: Action "test" complete.

04/13/2017 05:53:29: __COMPLETED__
~MPIWrapperMpi
=== Deleting training and test data
